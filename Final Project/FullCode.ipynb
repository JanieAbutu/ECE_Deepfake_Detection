{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CONFIGURATION SECTION\n",
    "# ================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay, classification_report)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision import models\n",
    "\n",
    "# -----------------------\n",
    "# REPRODUCIBILITY\n",
    "# -----------------------\n",
    "def set_seed(seed=42):\n",
    "    import random, numpy as np, torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def worker_init(worker_id):\n",
    "    np.random.seed(42 + worker_id)\n",
    "    random.seed(42 + worker_id)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# FILE PATH\n",
    "# -----------------------\n",
    "image_root_dir = \"/kaggle/input/faceforensics-extracted-dataset-c23/FF++C32-Frames\"\n",
    "ORIGINAL_CSV = \"/kaggle/input/faceforensics-extracted-dataset-c23/CSVs/Original.csv\"\n",
    "DEEPFAKES_CSV = \"/kaggle/input/faceforensics-extracted-dataset-c23/CSVs/Deepfakes.csv\"\n",
    "\n",
    "# -----------------------\n",
    "# TRAIN/VAL/TEST SPLITS\n",
    "# -----------------------\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "\n",
    "# IMAGE PREPROCESSING\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = (224, 224)\n",
    "num_workers = 2\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "LR = 1e-4\n",
    "num_epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'best_model_efficientnet_b7.pth'\n",
    "patience = 30\n",
    "epochs_no_improve = 0\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# BUILD DATAFRAME\n",
    "# ================================================================\n",
    "def build_combined_dataframe():\n",
    "    df_original = pd.read_csv(ORIGINAL_CSV)\n",
    "    df_deepfakes = pd.read_csv(DEEPFAKES_CSV)\n",
    "\n",
    "    df = pd.concat([df_original, df_deepfakes], ignore_index=True)\n",
    "\n",
    "    df['filepath'] = df.apply(\n",
    "        lambda r: os.path.join(image_root_dir, r['label'], r[\"filename\"]), axis=1\n",
    "    )\n",
    "\n",
    "    df['label_id'] = df['label'].map({\"Original\": 0, \"Deepfakes\": 1})\n",
    "    return df\n",
    "\n",
    "# ================================================================\n",
    "# DATASET\n",
    "# ================================================================\n",
    "class FFDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = read_image(row.filepath).float() / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(row[\"label_id\"], dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "# ================================================================\n",
    "# TRANSFORMS\n",
    "# ================================================================\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.ColorJitter(0.1, 0.1),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]  \n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# DATA LOADING\n",
    "# ================================================================\n",
    "df = build_combined_dataframe()\n",
    "transform = get_transforms()\n",
    "all_dataset = FFDataset(df, transform=transform)\n",
    "\n",
    "total_len = len(all_dataset)\n",
    "train_len = int(TRAIN_SPLIT * total_len)\n",
    "val_len = int(VAL_SPLIT * total_len)\n",
    "test_len = int(TEST_SPLIT * total_len)\n",
    "\n",
    "train_set, val_set, test_set = random_split(\n",
    "    all_dataset, [train_len, val_len, test_len]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=num_workers, worker_init_fn=worker_init, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=num_workers, worker_init_fn=worker_init, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=num_workers, worker_init_fn=worker_init, pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Train distribution:\", np.bincount([y for _, y in train_set]))\n",
    "print(\"Val distribution:\", np.bincount([y for _, y in val_set]))\n",
    "print(\"Test distribution:\", np.bincount([y for _, y in test_set]))\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# MODEL: EfficientNet-B7 (PRETRAINED)\n",
    "# ================================================================\n",
    "class EfficientNetB7Binary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = models.efficientnet_b7(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 1)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = EfficientNetB7Binary().to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for name, p in model.named_parameters():\n",
    "    print(name, p.requires_grad)\n",
    "\n",
    "# ================================================================\n",
    "# TRAINING LOOP\n",
    "# ================================================================\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # ---------------- TRAIN ----------------\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.float().to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).view(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        preds = torch.sigmoid(outputs).round()\n",
    "        all_train_labels.extend(labels.detach().cpu().numpy())\n",
    "        all_train_preds.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
    "\n",
    "    # ---------------- VALIDATION ----------------\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.float().to(DEVICE)\n",
    "\n",
    "            outputs = model(images).view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = accuracy_score(all_val_labels, all_val_preds)\n",
    "\n",
    "    # ---------------- CHECKPOINT ----------------\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Best model saved at: {best_model_path}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# ================================================================\n",
    "# LOAD BEST MODEL\n",
    "# ================================================================\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "print(\"Best model loaded\")\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# TEST EVALUATION\n",
    "# ================================================================\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(images).view(-1)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "\n",
    "# =================== METRICS ===================\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall    = recall_score(all_labels, all_preds)\n",
    "f1        = f1_score(all_labels, all_preds)\n",
    "accuracy  = accuracy_score(all_labels, all_preds)\n",
    "auroc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_labels, all_preds, digits=4)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Real\", \"Fake\"])\n",
    "\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auroc:.4f}')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
